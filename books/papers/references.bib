@inproceedings{Parthasarathy2022SelfsupervisedVP,
  title={Self-supervised video pretraining yields strong image representations},
  author={Nikhil Parthasarathy and S. M. Ali Eslami and Jo{\~a}o Carreira and Olivier J. H'enaff},
  year={2022},
  url={https://www.semanticscholar.org/paper/Self-supervised-video-pretraining-yields-strong-Parthasarathy-Eslami/c95527eed7758904823eb43300044fbd0cb1881c}
}

@misc{OriginalViT,
  doi = {10.48550/ARXIV.2010.11929},
  
  url = {https://arxiv.org/abs/2010.11929},
  
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{ViTFeatureAnal,
  title={Deep ViT Features as Dense Visual Descriptors},
  author={Shir Amir and Yossi Gandelsman and Shai Bagon and Tali Dekel},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.05814}
}